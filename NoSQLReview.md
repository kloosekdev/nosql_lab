| Nazwa           | Autor/Właściciel                            | Typ                                      | Zalety                                                                         | Wady                                                                                              | Kiedy używać                                                                          |
|------------------|----------------------------------------------|-------------------------------------------|---------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| Redshift        | Amazon                                      | Data Warehouse (kolumnowa)               | Redshift to w pełni zarządzany magazyn danych zoptymalizowany do analizy dużych zbiorów. Wykorzystuje kolumnowe przechowywanie danych i przetwarzanie MPP (Massively Parallel Processing), co zapewnia wysoką wydajność. Ścisła integracja z ekosystemem AWS (S3, Glue, Kinesis, QuickSight) ułatwia ETL, analizę i wizualizację danych. Duża wydajność przetwarzania danych analitycznych, szczególnie przy operacjach typu agregacje, joiny i skany dużych tabel.                                 | Koszty mogą rosnąć przy dużych zbiorach danych i intensywnym użytkowaniu, zwłaszcza przy funkcjach jak Concurrency Scaling. Przy dużej ilości danych i złożonych zapytaniach mogą wystąpić opóźnienia, szczególnie przy nieoptymalnej dystrybucji danych i braku indeksów. | Data warehousing w chmurze AWS                                                       |
| Delta Table     | Databricks                                  | Format zapisu / ACID table na Parquet    | Zapewnia transakcyjność ACID, co eliminuje problemy z niekompletnymi lub niespójnymi danymi. Funkcja time travel umożliwia przeglądanie i przywracanie wcześniejszych wersji danych. Zintegrowana z Apache Spark, wspiera zarówno batch jak i streaming, oferując wysoką wydajność dzięki optymalizacjom (Z-ordering, data skipping). | Ścisła zależność od Apache Spark i Databricks – pełna funkcjonalność dostępna głównie w tych środowiskach. Wdrożenie poza Spark/Databricks (np. w Presto/Trino) wymaga dodatkowej konfiguracji i może ograniczać funkcjonalność. | Gdy potrzebna jest historia danych, transakcyjność i skalowalność na plikach Parquet |
| Neo4j           | Neo4j, Inc.                                 | Grafowa                                  | Dzięki natywnej architekturze grafowej zapytania dotyczące relacji (np. friends of friends) są wyjątkowo szybkie. Zamiast kosztownych JOIN-ów, dane są bezpośrednio powiązane przez relacje. Język Cypher pozwala łatwo i czytelnie wyrażać złożone wzorce grafowe w sposób deklaratywny. | Nieoptymalna dla prostych, tabelarycznych danych – model grafowy komplikuje proste relacje. Operacje typowe dla RDBMS (np. agregacje, JOIN-y) są trudniejsze i mniej wydajne w grafowym podejściu. | Sieci społecznościowe, rekomendacje, wykrywanie oszustw                               |
| Redis           | Redis Ltd.                                  | Key-Value (in-memory)                    | Działa w pamięci RAM, zapewniając dostęp do danych z opóźnieniem submilisekundowym – idealny do cache i sesji. Obsługuje wiele struktur danych: listy, hashe, zbiory, zbiory posortowane, bitmapy, HLL (HyperLogLog - Szybkie liczenie unikalnych wartości np. adresy IP, zdarzenia w logach itd.), geodane – elastyczne modelowanie danych. | Działa w RAM – ilość danych ograniczona dostępną pamięcią, co może być kosztowne przy dużych zbiorach. Persistence wymaga konfiguracji (RDB - Redis Database Backup/Snapshotting, AOF - Append Only File/Log inkrementacyjny); domyślnie dane mogą zostać utracone po awarii lub restarcie. | Cache, kolejki, sesje użytkowników                                                    |
| Cassandra       | Apache                                      | Kolumnowa                                | Wysoka dostępność dzięki architekturze peer-to-peer – brak pojedynczego punktu awarii (brak centralnego serwera). Automatyczna replikacja między węzłami i centrami danych zwiększa odporność i niezawodność. Liniowa skalowalność – łatwe dodawanie nowych węzłów bez przestojów, rosnąca wydajność z każdym węzłem. | Model danych musi być projektowany pod konkretne zapytania – brak elastyczności i trudności przy zmianach schematu. Kompromisy spójności (CAP - Consistency, Availability, Partition Tolerance): trzeba balansować między dostępnością a spójnością, zależnie od poziomu consistency ustawionego dla zapisu/odczytu. | Systemy rozproszone z dużą dostępnością i skalą                                       |
| Google BigQuery  | Google           | Silnik OLAP (kolumnowy, serverless) | Wysoka wydajność zapytań SQL na dużych zbiorach danych dzięki kolumnowemu storage i rozdzieleniu warstw compute/storage. Architektura serverless – brak potrzeby zarządzania infrastrukturą, automatyczne skalowanie. Ścisła integracja z GCP – łatwe połączenie z usługami takimi jak Cloud Storage, Dataflow, AI Platform. | Model płatności za przetwarzane dane może generować wysokie koszty przy dużej liczbie zapytań lub źle zoptymalizowanych tabelach. Cold start – opóźnienia przy małych i rzadkich zapytaniach ze względu na dynamiczne przydzielanie zasobów. Brak klasycznych indeksów – wydajność zależy od partycjonowania i klastrowania tabel (porządkuje dane wewnątrz partycji lub całej tabeli). |elastyczność zapytań                                                                 | Systemy OLAP z dużą przepustowością                                                  |
 Google BigTable | Google                                      | Kolumnowa (wide-column store)            | Zaprojektowana do przetwarzania petabajtów danych – skalowalność rośnie liniowo z liczbą węzłów. Zapewnia niskie opóźnienia dostępu (rzędu ms), co czyni ją odpowiednią dla aplikacji wymagających szybkiego odczytu/zapisu. | Brak pełnego wsparcia dla SQL – wprowadzony GoogleSQL jest nadal w wersji pre-GA (pre-General Availability) i ma ograniczenia. Optymalna praca tylko przy operacjach po kluczach – brak wsparcia dla joinów i złożonych zapytań, co utrudnia elastyczną analizę danych. | Systemy OLTP z dużą przepustowością, gdy nie potrzeba złożonych zapytań SQL          |
| Druid           | Apache (Imply)                              | Kolumnowa, OLAP                          | Bardzo szybkie zapytania analityczne dzięki przechowywaniu danych kolumnowo, rozproszonemu przetwarzaniu i silnym indeksom bitmapowym. Wspiera przetwarzanie danych strumieniowych z Apache Kafka i Kinesis – umożliwia analitykę w czasie rzeczywistym z minimalnym opóźnieniem. | Złożona architektura – wiele typów węzłów (Broker, Historical, MiddleManager itd.) oraz zewnętrzne zależności (ZooKeeper, S3/HDFS). Wydajność wymaga tuningu – konieczne dostosowanie konfiguracji i modelu danych do charakterystyki zapytań. | Real-time analytics, dashboardy BI, monitorowanie                                    |
| HBase           | Apache                                      | Kolumnowa (na HDFS)                      | Skaluje się poziomo przez dodawanie nowych węzłów – dane dzielone są na regiony automatycznie rozpraszane po klastrze. Ścisła integracja z Hadoop i HDFS – współpracuje z MapReduce, Hive, Pig, Spark, co pozwala łączyć dostęp online z analizą batchową. | Złożona konfiguracja – wymaga uruchomienia i synchronizacji komponentów takich jak Hadoop, HDFS, ZooKeeper. Brak natywnego SQL – potrzebne dodatkowe narzędzia jak Phoenix do zapytań SQL. Wysokie opóźnienia przy zapytaniach ad-hoc – brak indeksów wtórnych i skanowanie tabeli poza kluczem wiersza. | Do analizy dużych ilości danych z dostępem w czasie rzeczywistym                      |
| FAISS           | Facebook AI Research                        | Vector database / Library                | Bardzo szybkie wyszukiwanie podobieństwa wektorów dzięki zaawansowanym indeksom (IVF, HNSW) i obsłudze GPU. Doskonała integracja z Pythonem – interfejs API zgodny z NumPy, prosty w użyciu i wydajny w prototypowaniu i wdrożeniach. | Brak wsparcia dla replikacji i skalowalności out-of-the-box – wymaga własnego zarządzania instancjami i podziału danych. Trudna integracja z systemami zewnętrznymi – brak REST API, SQL-like API, potrzebna dodatkowa logika aplikacyjna. | W systemach ML/AI do wyszukiwania podobnych wektorów (np. obrazy, embeddingi)         |
| Annoy           | Spotify                                     | Vector database / Library                | Lekka biblioteka z niskim zużyciem pamięci – indeksy są mapowane do pamięci i mogą być współdzielone między procesami. Szybka i łatwa w użyciu – dobra do wyszukiwania podobieństw w statycznych danych, idealna do systemów rekomendacyjnych i embedów offline. | Brak możliwości aktualizacji indeksu – każda zmiana danych wymaga pełnej przebudowy. Słabe wsparcie dla dynamicznych zbiorów danych – indeksy są zoptymalizowane pod dane statyczne, a tworzenie dużych indeksów bywa czasochłonne. | Do rekomendacji i prostych wyszukiwań podobieństwa, gdy dane nie zmieniają się często |
| Qdrant          | Qdrant                                      | Vector database                          | Wygodne REST API umożliwia łatwą integrację i zarządzanie danymi. Zaawansowane filtrowanie – można stosować warunki na metadanych przy wyszukiwaniu wektorowym bez utraty wydajności. Obsługuje wyszukiwanie zarówno wektorowe, jak i skalarne – pozwala na precyzyjne i elastyczne zapytania. | Stosunkowo nowy projekt (od 2021) – mniejsza liczba użytkowników i mniej zasobów społecznościowych niż w dojrzałych projektach jak FAISS. Mniej gotowych przykładów, integracji i pluginów open source – może wymagać więcej pracy przy wdrożeniu niestandardowych rozwiązań. | W aplikacjach AI, chatbotach, systemach rekomendacyjnych z dynamicznymi danymi         |
| Elasticsearch   | Elastic NV                                  | Wyszukiwanie pełnotekstowe / Dokumentowa | Szybkie i zaawansowane wyszukiwanie tekstowe dzięki silnikowi Lucene – obsługuje fuzzy search, autocomplete, stemming. Skalowalność pozioma – łatwe dodawanie węzłów, shardowanie i replikacja danych zapewniają wydajność i odporność na awarie. | Wysokie zużycie CPU i RAM – zwłaszcza przy dużej liczbie shardów lub złożonych zapytaniach i agregacjach. Wymaga tuningu – konieczna optymalizacja liczby shardów, konfiguracji JVM i monitorowanie metryk dla zachowania wydajności klastra. | Wyszukiwanie pełnotekstowe, logi, analityka                                          |
| MongoDB         | MongoDB Inc.                                | Dokumentowa                              | Elastyczny model dokumentowy BSON – pozwala na przechowywanie danych bez sztywnego schematu, łatwe dodawanie nowych pól. Naturalne dopasowanie do obiektowych struktur danych – łatwa integracja z aplikacjami w Pythonie, JS, Javie itd. Bogaty ekosystem narzędzi i wsparcie wielu języków programowania ułatwiają wdrażanie i rozwój aplikacji. | Bez odpowiednich indeksów zapytania powodują pełne skanowanie kolekcji (collection scan), co znacząco obniża wydajność przy dużych zbiorach danych. Brak indeksów prowadzi do wysokiego zużycia CPU i RAM oraz długiego czasu odpowiedzi – indeksowanie jest kluczowe dla optymalizacji. | Aplikacje webowe, prototypowanie, JSON-like dane                                     |
| Presto DB       | Meta (Facebook), Presto Software Foundation | Silnik SQL rozproszony                   | Presto umożliwia wykonywanie zapytań SQL na wielu źródłach danych jednocześnie (federated queries). Działa z różnymi typami źródeł – HDFS, S3, RDBMS, NoSQL – bez konieczności przenoszenia danych. Dzięki architekturze rozproszonej i przetwarzaniu kolumnowemu zapewnia wysoką wydajność zapytań OLAP.                   | Nie posiada własnego storage – pełni jedynie rolę silnika zapytań SQL. Zależny od zewnętrznych źródeł danych (HDFS, S3, bazy SQL), co wpływa na wydajność i zarządzanie. Brak trwałego przechowywania wyników – wymaga dodatkowych systemów do ich zapisu. | Szybka analiza danych z wielu źródeł                                                 |
| Apache Impala   | Apache (Cloudera)                           | SQL-on-Hadoop                            | Szybkie zapytania SQL bez MapReduce – bezpośrednie, niskolatencyjne przetwarzanie danych z HDFS i Parquet. Integracja z Hive Metastore – wspólne metadane umożliwiają współdzielenie definicji tabel między Hive i Impala. | Złożona integracja z ekosystemem Hadoop – wymaga współpracy z HDFS, Hive Metastore i opcjonalnie YARN. Wiele usług musi być aktywnych i kompatybilnych – trudniejsze wdrożenie i utrzymanie. Dodatkowe obciążenie zasobów przez demony działające na każdym węźle klastra. | Analiza danych na Hadoop w czasie rzeczywistym                                       |
| Hive            | Apache                                      | SQL-on-Hadoop                            | Zgodność z SQL – użytkownicy mogą używać języka HiveQL, zbliżonego do standardowego SQL, bez konieczności pisania MapReduce. Integracja z ekosystemem Hadoop – pełne wsparcie dla HDFS, YARN i kompatybilność z innymi narzędziami jak HBase, Tez, Spark. | Hive używa wsadowego przetwarzania (np. MapReduce), co powoduje długie czasy odpowiedzi. Brakuje wsparcia dla interaktywnego wykonywania zapytań ad-hoc bez rozszerzeń typu LLAP (Low-Latency Analytical Processing).                                                     | Przetwarzanie wsadowe dużych ilości danych                                           |
| AWS Athena      | Amazon                                      | Silnik SQL na S3 (serverless)            | Usługa serverless – brak potrzeby zarządzania infrastrukturą, skalowaniem czy konfiguracją. Model płatności pay-per-query – opłata tylko za dane przetworzone w zapytaniu. Bezpośrednia integracja z Amazon S3 – możliwość wykonywania zapytań SQL bezpośrednio na danych w S3. | Opóźnienia – każdorazowe skanowanie danych z S3 może wydłużać czas odpowiedzi, szczególnie przy dużych zbiorach. Brak kontroli nad backendem – brak możliwości konfiguracji silnika zapytań i alokacji zasobów, co utrudnia optymalizację i debugowanie. |
